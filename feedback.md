# Week 5 Feedback: CodeGen / Planning

**Authors:** [Gavin Deane, Artemiy Vishnyakov, Savira Umar]

## 1. Counterexample Problems

### Problem A_1:  [Gavin Deane]

**Task Description:**

Complete the function that takes a paragraph of text and returns a count of how many times each word appears.

Here is an example input/output pair:

Input (string):
"The quick brown fox jumps over the lazy dog. The dog was not lazy, but the fox was quick."

Output (csv):
Word,Count
the,4
quick,2
fox,2
lazy,2
dog,2
was,2
brown,1
jumps,1
over,1
not,1
but,1

**Starter Code:**

The function and example test file is found in https://github.com/GDeane/CS846_week6_counterexample/tree/main/Week5/A_1.

> A note on GenAI contribution: The code examples and test files were generated using GitHub Copilot: GPT-5.1-Codex-Max

---

### 2. Guidelines that didn't work for Problem A_1

#### Guideline 2: Add Algorithmic details when logic is complex

**Prompt and Context:**

Context Given: Week6/A_1/problem_A_1.py Week6/A_1/tests/test_problem_A_1.py

> "Write a function to count word frequencies in a string. To ensure O(n) time complexity and avoid the overhead of
> high-level abstractions, implement a Trie (prefix tree) where each node stores a frequency counter. Traverse the
> string
> character by character to populate the Trie."

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

```python
class TrieNode:
    def __init__(self):
        self.children = {}
        self.freq = 0


def count_word_frequencies(text: str) -> Dict[str, int]:
    """Return a dict of lowercase words -> counts for the given text.

    Replace the body with your implementation. The current placeholder raises
    NotImplementedError so tests will fail until you implement it.
    """
    root = TrieNode()
    current_word = ""

    def insert(word):
        node = root
        for char in word:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.freq += 1

    for char in text:
        if char.isalpha() or char == "'":
            current_word += char.lower()
        else:
            if current_word:
                insert(current_word)
                current_word = ""
    if current_word:
        insert(current_word)

    # Collect the result
    result = {}
    def collect(node, prefix):
        if node.freq > 0:
            result[prefix] = node.freq
        for char, child in node.children.items():
            collect(child, prefix + char)
    collect(root, "")
    return result
```

**Why this is sub-optimal:**

This function is "overly clever". It requires a developer who reads it to understand the trie class, and is very prone
to bugs if any change has to be made to it. This makes it very hard to maintain.

---

### 3. New and Updated Guidelines that worked for Problem A_1

#### Guideline 2 (Revised): Specify Clear Requirements without prescribing algorithm

**Description:**

As in good requirements engineering, give the LLM clear requirements on the problem you want solved and what a
definition of done means, but do not prescribe algorithmic details.

**Reasoning:**

Prescribing algorithmic details often leads to code that might be slightly more efficient, but is overly clever and
challenging to read for other developers. This violates the KISS (Keep it simple, Stupid) principle of good code.

Prescribing algorithm also usually leads to new and untested code being created. Rather than making use of common and
thoroughly validated library functions.

**Prompt and Context:**

Context Given: Week6/A_1/problem_A_1.py Week6/A_1/tests/test_problem_A_1.py

> "In problem_A_1.py Write the function to count word frequencies in a string. The function should take in a string of
> text and return a count of how many times each word appears."

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

```python
import re
from collections import Counter
from typing import Dict


def count_word_frequencies(text: str) -> Dict[str, int]:
    """Return a dict of lowercase words -> counts for the given text.

    Replace the body with your implementation. The current placeholder raises
    NotImplementedError so tests will fail until you implement it.
    """
    text = text.lower()
    words = re.findall(r"[a-z']+", text)
    return dict(Counter(words))
```

**Result:**

This output is highly elegant and understandable, even to someone with little understanding of Python. It relies on
thoroughly tested and optimized library functions and each step is easy to understand conceptually.

It is also very likely that the second function is significantly faster due to the optimization of library functions. In
addition, collections.Counter is optimized in C, making it substantially more performant than a manual Python trie.

---

### Problem B_1:  [Artemiy Vishnyakov]

**Task Description:**
Create a program to generate a dataframe of specified byte size, populate it with randomly generated data, and then get the sums of columns as a scaffold for some data science project.

**Starter Code:**

The function and example test file is found in https://github.com/GDeane/CS846_week6_counterexample/tree/main/Week5/B_1.

> A note on GenAI contribution: The guidelines were tested using Grok Code Fast 1 (which is now no longer a 0x model?) to create the examples.

---

### 2. Guidelines that didn't work for Problem B_1

#### Guideline 3: Specify required external libraries/packages and their purpose.

**Prompt and Context:**

Context Given: Problem_B_1.py

> "Fill the DataFrameProcessor Python class to generate a CSV of some KB size with randomly generated data and compute the sum of each column in it. Use pandas for tabular data manipulation."

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

```python
import pandas as pd
import numpy as np

def generateCSV(KB):
    num_cols = 10
    num_rows = (KB * 1024) // 100  # rough estimate for size
    df = pd.DataFrame(np.random.rand(num_rows, num_cols))
    df.to_csv('data.csv', index=False)

class DataFrameProcessor:
    def __init__(self):
        pass

    def read_csv(self):
        df = pd.read_csv('data.csv')
        sums = df.sum()
        return sums

```

**Why this is sub-optimal:**
The solution is too simple:
- If `data.csv` is multi-GB, `pd.read_csv` will likely OOM because pandas loads the dataset into memory.
- The prompt did not specify version constraints, install commands, or whether an out-of-core solution is acceptable.

---

### 3. New and Updated Guidelines that worked for Problem B_1

#### Guideline 3 (Revised): Specify required external libraries/packages and their purpose.

**Description:**
When asking an LLM to use external libraries, include the following if known and relevant:
1. Package name and explicit version constraint (or minimum version).
2. Intended purpose and which APIs/features to use.
3. Classification: runtime, test, or dev dependency.
4. Platform/hardware constraints (OS, CPU/GPU).
5. Expected data scale and memory/performance limits.
6. Preferred alternatives and a rule for when to switch.
7. Install command(s) and how to declare the dependency (requirements.txt / pyproject / environment.yml).
8. A minimal usage snippet or expected function signature.

If multiple libraries are acceptable, state the preferred one and a simple threshold (e.g., file size) for switching to an alternative.

**Reasoning:**
By providing detailed library specifications, LLMs generate code that accounts for scale, compatibility, and alternatives, avoiding failures like OOM on large data and ensuring production-ready outputs.

**Prompt and Context:**

Context Given: Problem_B_1.py

> "Write a Python script that computes the sum of each numeric column in a CSV file. Dependencies:
- Use `pandas>=1.5` for files smaller than 500 MB (runtime dependency).
- Use `dask[complete]>=2023.6` for files >= 500 MB (runtime dependency).
Target environment: Linux server with 16 GB RAM, CPU only. Provide install commands for both options, a `requirements.txt` snippet, and two minimal working examples (pandas path and dask path). Explain the choice for each path."

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

**Result:**

```python
# Install commands:
# For pandas (files < 500 MB): pip install 'pandas>=1.5'
# For dask (files >= 500 MB): pip install 'dask[complete]>=2023.6'
#
# requirements.txt snippet:
# pandas>=1.5
# dask[complete]>=2023.6

import pandas as pd
import numpy as np
import dask.dataframe as dd
import dask.array as da
import os

def generateCSV(KB):
    # Estimate number of rows to achieve approximately KB KB size
    # Assuming 10 numeric columns, each ~10 bytes in CSV, plus overhead ~100 bytes per row
    bytes_per_row = 100
    target_bytes = KB * 1024
    num_rows = max(1, target_bytes // bytes_per_row)
    num_cols = 10
    df = pd.DataFrame(np.random.rand(num_rows, num_cols), columns=[f'col{i}' for i in range(num_cols)])
    df.to_csv("data.csv", index=False)

class DataFrameProcessor:
    def __init__(self):
        self.file_path = "data.csv"

    def read_csv(self):
        if not os.path.exists(self.file_path):
            raise FileNotFoundError(f"File {self.file_path} does not exist")
        
        file_size = os.path.getsize(self.file_path)
        threshold = 500 * 1024 * 1024  # 500 MB in bytes
        
        if file_size < threshold:
            # Use pandas for files < 500 MB
            df = pd.read_csv(self.file_path)
            sums = df.sum(numeric_only=True)
        else:
            # Use dask for files >= 500 MB
            df = dd.read_csv(self.file_path)
            sums = df.sum().compute()
        
        return sums
```

---

### Problem C_1:  [Savira Umar]

**Task Description:**

**Starter Code:**

The function and example test file is found in https://github.com/GDeane/CS846_week6_counterexample/tree/main/Week5/C_1.

> A note on GenAI contribution: The code examples and test files were generated using GitHub Copilot: GPT-5.1-Codex-Max

---

### 2. Guidelines that didn't work for Problem C_1

#### Guideline X:

**Prompt and Context:**

Context Given:

> ""

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

**Why this is sub-optimal:**



---

### 3. New and Updated Guidelines that worked for Problem C_1

#### Guideline X (Revised):

**Description:**

**Reasoning:**

**Prompt and Context:**

Context Given:

> ""

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

**Result:**



---