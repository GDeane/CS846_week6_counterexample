# Week 5 Feedback: CodeGen / Planning

**Authors:** [Gavin Deane, Artemiy Vishnyakov, Savira Umar]

## 1. Counterexample Problems

### Problem A_1:  [Gavin Deane]

**Task Description:**

Complete the function that takes a paragraph of text and returns a count of how many times each word appears.

Here is an example input/output pair:

Input (string):
"The quick brown fox jumps over the lazy dog. The dog was not lazy, but the fox was quick."

Output (csv):
Word,Count
the,4
quick,2
fox,2
lazy,2
dog,2
was,2
brown,1
jumps,1
over,1
not,1
but,1

**Starter Code:**

The function and example test file is found in https://github.com/GDeane/CS846_week6_counterexample/tree/main/Week5/A_1.

> A note on GenAI contribution: The code examples and test files were generated using GitHub Copilot: GPT-5.1-Codex-Max

---

### 2. Guidelines that didn't work for Problem A_1

#### Guideline 2: Add Algorithmic details when logic is complex

**Prompt and Context:**

Context Given: Week6/A_1/problem_A_1.py Week6/A_1/tests/test_problem_A_1.py

> "Write a function to count word frequencies in a string. To ensure O(n) time complexity and avoid the overhead of
> high-level abstractions, implement a Trie (prefix tree) where each node stores a frequency counter. Traverse the
> string
> character by character to populate the Trie."

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

```python
class TrieNode:
    def __init__(self):
        self.children = {}
        self.freq = 0


def count_word_frequencies(text: str) -> Dict[str, int]:
    """Return a dict of lowercase words -> counts for the given text.

    Replace the body with your implementation. The current placeholder raises
    NotImplementedError so tests will fail until you implement it.
    """
    root = TrieNode()
    current_word = ""

    def insert(word):
        node = root
        for char in word:
            if char not in node.children:
                node.children[char] = TrieNode()
            node = node.children[char]
        node.freq += 1

    for char in text:
        if char.isalpha() or char == "'":
            current_word += char.lower()
        else:
            if current_word:
                insert(current_word)
                current_word = ""
    if current_word:
        insert(current_word)

    # Collect the result
    result = {}
    def collect(node, prefix):
        if node.freq > 0:
            result[prefix] = node.freq
        for char, child in node.children.items():
            collect(child, prefix + char)
    collect(root, "")
    return result
```

**Why this is sub-optimal:**

This function is "overly clever". It requires a developer who reads it to understand the trie class, and is very prone
to bugs if any change has to be made to it. This makes it very hard to maintain.

---

### 3. New and Updated Guidelines that worked for Problem A_1

#### Guideline 2 (Revised): Specify Clear Requirements without prescribing algorithm

**Description:**

As in good requirements engineering, give the LLM clear requirements on the problem you want solved and what a
definition of done means, but do not prescribe algorithmic details.

**Reasoning:**

Prescribing algorithmic details often leads to code that might be slightly more efficient, but is overly clever and
challenging to read for other developers. This violates the KISS (Keep it simple, Stupid) principle of good code.

Prescribing algorithm also usually leads to new and untested code being created. Rather than making use of common and
thoroughly validated library functions.

**Prompt and Context:**

Context Given: Week6/A_1/problem_A_1.py Week6/A_1/tests/test_problem_A_1.py

> "In problem_A_1.py Write the function to count word frequencies in a string. The function should take in a string of
> text and return a count of how many times each word appears."

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

```python
import re
from collections import Counter
from typing import Dict


def count_word_frequencies(text: str) -> Dict[str, int]:
    """Return a dict of lowercase words -> counts for the given text.

    Replace the body with your implementation. The current placeholder raises
    NotImplementedError so tests will fail until you implement it.
    """
    text = text.lower()
    words = re.findall(r"[a-z']+", text)
    return dict(Counter(words))
```

**Result:**

This output is highly elegant and understandable, even to someone with little understanding of Python. It relies on
thoroughly tested and optimized library functions and each step is easy to understand conceptually.

It is also very likely that the second function is significantly faster due to the optimization of library functions. In
addition, collections.Counter is optimized in C, making it substantially more performant than a manual Python trie.

---

### Problem B_1:  [Artemiy Vishnyakov]

**Task Description:**
Create a program to generate a dataframe of specified byte size, populate it with randomly generated data, and then get the sums of columns as a scaffold for some data science project.

**Starter Code:**

The function and example test file is found in https://github.com/GDeane/CS846_week6_counterexample/tree/main/Week5/B_1.

> A note on GenAI contribution: The guidelines were tested using Grok Code Fast 1 (which is now no longer a 0x model?) to create the examples.

---

### 2. Guidelines that didn't work for Problem B_1

#### Guideline 3: Specify required external libraries/packages and their purpose.

**Prompt and Context:**

Context Given: Problem_B_1.py

> "Fill the DataFrameProcessor Python class to generate a CSV of some KB size with randomly generated data and compute the sum of each column in it. Use pandas for tabular data manipulation."

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

```python
import pandas as pd
import numpy as np

def generateCSV(KB):
    num_cols = 10
    num_rows = (KB * 1024) // 100  # rough estimate for size
    df = pd.DataFrame(np.random.rand(num_rows, num_cols))
    df.to_csv('data.csv', index=False)

class DataFrameProcessor:
    def __init__(self):
        pass

    def read_csv(self):
        df = pd.read_csv('data.csv')
        sums = df.sum()
        return sums

```

**Why this is sub-optimal:**
The solution is too simple:
- If `data.csv` is multi-GB, `pd.read_csv` will likely OOM because pandas loads the dataset into memory.
- The prompt did not specify version constraints, install commands, or whether an out-of-core solution is acceptable.

---

### 3. New and Updated Guidelines that worked for Problem B_1

#### Guideline 3 (Revised): Specify required external libraries/packages and their purpose.

**Description:**
When asking an LLM to use external libraries, include the following if known and relevant:
1. Package name and explicit version constraint (or minimum version).
2. Intended purpose and which APIs/features to use.
3. Classification: runtime, test, or dev dependency.
4. Platform/hardware constraints (OS, CPU/GPU).
5. Expected data scale and memory/performance limits.
6. Preferred alternatives and a rule for when to switch.
7. Install command(s) and how to declare the dependency (requirements.txt / pyproject / environment.yml).
8. A minimal usage snippet or expected function signature.

If multiple libraries are acceptable, state the preferred one and a simple threshold (e.g., file size) for switching to an alternative.

**Reasoning:**
By providing detailed library specifications, LLMs generate code that accounts for scale, compatibility, and alternatives, avoiding failures like OOM on large data and ensuring production-ready outputs.

**Prompt and Context:**

Context Given: Problem_B_1.py

> "Write a Python script that computes the sum of each numeric column in a CSV file. Dependencies:
- Use `pandas>=1.5` for files smaller than 500 MB (runtime dependency).
- Use `dask[complete]>=2023.6` for files >= 500 MB (runtime dependency).
Target environment: Linux server with 16 GB RAM, CPU only. Provide install commands for both options, a `requirements.txt` snippet, and two minimal working examples (pandas path and dask path). Explain the choice for each path."

**Solution or Output generated by GitHub Copilot (Grok Code Fast 1):**

**Result:**

```python
# Install commands:
# For pandas (files < 500 MB): pip install 'pandas>=1.5'
# For dask (files >= 500 MB): pip install 'dask[complete]>=2023.6'
#
# requirements.txt snippet:
# pandas>=1.5
# dask[complete]>=2023.6

import pandas as pd
import numpy as np
import dask.dataframe as dd
import dask.array as da
import os

def generateCSV(KB):
    # Estimate number of rows to achieve approximately KB KB size
    # Assuming 10 numeric columns, each ~10 bytes in CSV, plus overhead ~100 bytes per row
    bytes_per_row = 100
    target_bytes = KB * 1024
    num_rows = max(1, target_bytes // bytes_per_row)
    num_cols = 10
    df = pd.DataFrame(np.random.rand(num_rows, num_cols), columns=[f'col{i}' for i in range(num_cols)])
    df.to_csv("data.csv", index=False)

class DataFrameProcessor:
    def __init__(self):
        self.file_path = "data.csv"

    def read_csv(self):
        if not os.path.exists(self.file_path):
            raise FileNotFoundError(f"File {self.file_path} does not exist")
        
        file_size = os.path.getsize(self.file_path)
        threshold = 500 * 1024 * 1024  # 500 MB in bytes
        
        if file_size < threshold:
            # Use pandas for files < 500 MB
            df = pd.read_csv(self.file_path)
            sums = df.sum(numeric_only=True)
        else:
            # Use dask for files >= 500 MB
            df = dd.read_csv(self.file_path)
            sums = df.sum().compute()
        
        return sums
```

---

### Problem C_1: \[Savira Umar\]

**Task Description:**\
Implement and explain `plugin_loader.py` (loads JSON config, resolves
module, imports plugins dynamically, builds a pipeline).

**Starter Code:**

The function and example test file is found in https://github.com/GDeane/CS846_week6_counterexample/tree/main/Week5/C_1.

A note on GenAI contribution:\
The counterexample prompts and structured documentation were generated
using GitHub Copilot (Grok Code Fast 1).

---

### 2. Guidelines That Didn't Work for Problem C_1

---

#### Guideline 2: Add Algorithmic Details When Logic Is Complex

---

#### Prompt and Context

**Context Given:**\
`Week6/plugin_loader.py`

**Prompt (Original applying Guideline 2):**

> Implement `plugin_loader.py` using an efficient algorithmic approach.
> Ensure optimal time complexity. Avoid redundant operations. Explain
> algorithmic design decisions clearly.

---

#### Solution or Output Generated by GitHub Copilot (Grok Code Fast 1)
```python
import importlib
import json
import os
from typing import Callable, Dict, Any


def load_config(path: str) -> Dict[str, Any]:
    """
    Loads JSON configuration from file.
    Time complexity: O(1) assuming small config file; dominated by I/O and JSON parsing.
    Algorithmic decision: Direct file read and JSON load for simplicity and efficiency; no caching as configs may change.
    """
    with open(path, "r") as f:
        return json.load(f)


def resolve_module_name(config: Dict[str, Any]) -> str:
    """
    Resolves plugin module name from environment or config.
    Time complexity: O(1) for dict access and env var check.
    Algorithmic decision: Environment variable takes precedence for runtime flexibility; fallback to config for defaults.
    """
    return os.getenv("PLUGINS_MODULE", config.get("module", "plugins"))


def load_plugins(module_name: str) -> Dict[str, Callable[..., Any]]:
    """
    Dynamically imports module and retrieves plugin registry.
    Time complexity: O(1) for import and attribute access; importlib caches modules to avoid redundant loading.
    Algorithmic decision: Use importlib for dynamic loading; assumes REGISTRY is a dict for O(1) lookups.
    """
    module = importlib.import_module(module_name)
    return getattr(module, "REGISTRY")


def build_pipeline(registry: Dict[str, Callable[..., Any]], steps: list[str]) -> Callable[[str], str]:
    """
    Builds a pipeline by pre-resolving callables from registry.
    Time complexity: O(m) where m is len(steps), for precomputing callable list; execution is O(m) with no per-step lookups.
    Algorithmic decision: Pre-resolve callables into a list to eliminate dict lookups during execution, optimizing for repeated pipeline use.
    Avoids redundant registry access; uses list for sequential iteration.
    """
    funcs = [registry[step] for step in steps]  # Pre-resolve to avoid O(1) lookups per execution
    def pipeline(text: str) -> str:
        for func in funcs:
            text = func(text)
        return text
    return pipeline


def init_pipeline(config_path: str) -> Callable[[str], str]:
    """
    Initializes the full pipeline from config file.
    Time complexity: O(m) dominated by build_pipeline; other steps O(1).
    Algorithmic decision: Sequential composition for clarity; no memoization as init may be called with different paths.
    """
    config = load_config(config_path)
    module_name = resolve_module_name(config)
    registry = load_plugins(module_name)
    steps = config["steps"]
    return build_pipeline(registry, steps)
```
---

#### Why This Is Sub-Optimal

This output is weak for this task because:

- There is no meaningful algorithmic decision â€” the pipeline must apply steps sequentially.
- The complexity in this problem is integration-based, not computational.
- The real risks are:
- Config schema validation
- Module export validation (REGISTRY / get_registry())
- Step existence validation
- Clear and consistent failure modes
- Over-emphasizing performance distracts from correctness and maintainability.

Guideline 2 works for algorithm-heavy problems, but here it pushes
optimization in the wrong dimension.

---

### 3. New and Updated Guidelines That Worked for Problem C_1

---

#### Guideline 2: Match the "Detail Type" to the "Complexity Type"

---

#### Description

When logic is complex, align the detail type with where complexity
actually lives:

- If complexity is **algorithmic**, specify algorithm and complexity
  target.
- If complexity is **contractual/integration-based**, specify:
  - Required config structure\
  - Required module exports\
  - Registry shape requirements\
  - Explicit validation rules\
  - Clear exception strategy

---

#### Prompt and Context

**Improved Prompt:**

> Improve `plugin_loader.py` by focusing on correctness and failure
> handling instead of algorithmic complexity.\
> Add validation for: - Missing `"steps"` in config\
>
> - Missing `REGISTRY` / `get_registry()`\
> - Unknown plugin step names\
>   Explain what errors will be raised and where.

---

#### Solution or Output Generated by GitHub Copilot (Grok Code Fast 1)
```python
import importlib
import json
import os
from typing import Callable, Dict, Any


def load_config(path: str) -> Dict[str, Any]:
    """
    Loads JSON configuration from file.
    Raises: FileNotFoundError if path does not exist; json.JSONDecodeError if invalid JSON.
    """
    with open(path, "r") as f:
        return json.load(f)


def resolve_module_name(config: Dict[str, Any]) -> str:
    """
    Resolves plugin module name from environment or config.
    """
    return os.getenv("PLUGINS_MODULE", config.get("module", "plugins"))


def load_plugins(module_name: str) -> Dict[str, Callable[..., Any]]:
    """
    Dynamically imports module and retrieves plugin registry.
    Raises: ModuleNotFoundError if module cannot be imported; AttributeError if module lacks 'REGISTRY' attribute.
    """
    module = importlib.import_module(module_name)
    if not hasattr(module, "REGISTRY"):
        raise AttributeError(f"Module '{module_name}' does not have a 'REGISTRY' attribute.")
    registry = getattr(module, "REGISTRY")
    return registry


def build_pipeline(registry: Dict[str, Callable[..., Any]], steps: list[str]) -> Callable[[str], str]:
    """
    Builds a pipeline by pre-resolving callables from registry.
    Raises: ValueError if any step name is not in the registry.
    """
    for step in steps:
        if step not in registry:
            raise ValueError(f"Unknown plugin step: '{step}'")
    funcs = [registry[step] for step in steps]  # Pre-resolve to avoid O(1) lookups per execution
    def pipeline(text: str) -> str:
        for func in funcs:
            text = func(text)
        return text
    return pipeline


def init_pipeline(config_path: str) -> Callable[[str], str]:
    """
    Initializes the full pipeline from config file.
    Raises: ValueError if config lacks 'steps' key.
    """
    config = load_config(config_path)
    if "steps" not in config:
        raise ValueError("Config must contain 'steps' key.")
    module_name = resolve_module_name(config)
    registry = load_plugins(module_name)
    steps = config["steps"]
    return build_pipeline(registry, steps)
---
```

#### Result

The revised approach:

- Focused on correctness
- Reduced unnecessary optimization
- Improved maintainability
- Better aligned with the true complexity of the task

This demonstrates that Guideline 2 must adapt to the type of complexity
present.

---
